{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69e46621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory created: ../outputs/figures/modeling\n",
      "Models directory created: ../outputs/models\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 03_modeling.ipynb\n",
    "# Model Training and Evaluation for Multi-Class Diabetes Classification\n",
    "# Dataset: BRFSS 2015 - Diabetes Health Indicators (3 Classes)\n",
    "# \n",
    "# OPTIMIZATION GOAL: HIGH RECALL\n",
    "# Medical Context: In diabetes screening, it is more important to identify\n",
    "# all potential diabetes cases (high recall) even if it means some false \n",
    "# positives. Missing a diabetes case (false negative) has more serious \n",
    "# health consequences than a false alarm (false positive).\n",
    "# ============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add src directory to path to import custom modules\n",
    "sys.path.append('../src/core')\n",
    "\n",
    "# Import custom modules for feature engineering and modeling\n",
    "from feature_engineering import apply_all_feature_engineering\n",
    "from modeling import (\n",
    "    train_logistic_regression,\n",
    "    train_random_forest,\n",
    "    train_xgboost,\n",
    "    train_svm,\n",
    "    evaluate_model,\n",
    "    plot_confusion_matrix,\n",
    "    plot_classification_report,\n",
    "    plot_roc_curves,\n",
    "    compare_models,\n",
    "    save_model\n",
    ")\n",
    "\n",
    "# Scikit-learn imports for scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Configure plot style for consistent visualizations\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"colorblind\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Define output directories for saving visualizations and models\n",
    "output_dir = \"../outputs/figures/modeling\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(f\"Output directory created: {output_dir}\")\n",
    "\n",
    "models_dir = \"../outputs/models\"\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "print(f\"Models directory created: {models_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbe2418",
   "metadata": {},
   "source": [
    "# Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78d84368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 1: LOAD PREPROCESSED DATA\n",
      "================================================================================\n",
      "\n",
      "DATA SHAPES:\n",
      "------------------------------------------------------------\n",
      "Training Set (Original):     (183824, 21)\n",
      "Training Set (SMOTE):        (456129, 21)\n",
      "Test Set:                    (45957, 21)\n",
      "\n",
      "TARGET DISTRIBUTION:\n",
      "------------------------------------------------------------\n",
      "Training Set (Original):\n",
      "Diabetes_012\n",
      "0.0    152043\n",
      "1.0      3703\n",
      "2.0     28078\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Training Set (SMOTE):\n",
      "Diabetes_012\n",
      "0.0    152043\n",
      "1.0    152043\n",
      "2.0    152043\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test Set:\n",
      "Diabetes_012\n",
      "0.0    38012\n",
      "1.0      926\n",
      "2.0     7019\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 1. LOAD PREPROCESSED DATA\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 1: LOAD PREPROCESSED DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load scaled training and test data\n",
    "# These datasets have continuous features scaled (StandardScaler)\n",
    "# Binary and ordinal features remain unchanged\n",
    "features_train = pd.read_csv(\"../data/processed/features_train_scaled.csv\")\n",
    "features_test = pd.read_csv(\"../data/processed/features_test_scaled.csv\")\n",
    "\n",
    "# Load target variables\n",
    "# squeeze() converts single-column DataFrame to Series\n",
    "target_train = pd.read_csv(\"../data/processed/target_train.csv\").squeeze()\n",
    "target_test = pd.read_csv(\"../data/processed/target_test.csv\").squeeze()\n",
    "\n",
    "# Load SMOTE-resampled training data\n",
    "# SMOTE (Synthetic Minority Over-sampling Technique) creates synthetic samples\n",
    "# for minority classes to balance the dataset\n",
    "features_train_smote = pd.read_csv(\"../data/processed/features_train_smote.csv\")\n",
    "target_train_smote = pd.read_csv(\"../data/processed/target_train_smote.csv\").squeeze()\n",
    "\n",
    "# Display data shapes to verify successful loading\n",
    "print(\"\\nDATA SHAPES:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Training Set (Original):     {features_train.shape}\")\n",
    "print(f\"Training Set (SMOTE):        {features_train_smote.shape}\")\n",
    "print(f\"Test Set:                    {features_test.shape}\")\n",
    "\n",
    "# Display target distribution to understand class imbalance\n",
    "# Class 0 = No Diabetes\n",
    "# Class 1 = Prediabetes\n",
    "# Class 2 = Diabetes\n",
    "print(\"\\nTARGET DISTRIBUTION:\")\n",
    "print(\"-\" * 60)\n",
    "print(\"Training Set (Original):\")\n",
    "print(target_train.value_counts().sort_index()) # pyright: ignore[reportAttributeAccessIssue]\n",
    "print(\"\\nTraining Set (SMOTE):\")\n",
    "print(target_train_smote.value_counts().sort_index()) # pyright: ignore[reportAttributeAccessIssue]\n",
    "print(\"\\nTest Set:\")\n",
    "print(target_test.value_counts().sort_index()) # pyright: ignore[reportAttributeAccessIssue]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c4dfbf",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b45d0cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 2: FEATURE ENGINEERING\n",
      "================================================================================\n",
      "\n",
      "APPLYING FEATURE ENGINEERING:\n",
      "------------------------------------------------------------\n",
      "Creating new features:\n",
      "  • HealthRiskScore: Sum of risk factors (HighBP, HighChol, Stroke, etc.)\n",
      "  • LifestyleScore: Sum of positive health habits (PhysActivity, Fruits, Veggies)\n",
      "  • BMI Categories: One-hot encoded BMI groups (Underweight, Normal, Overweight, Obese)\n",
      "  • Age Groups: One-hot encoded age groups (Young, Middle, Senior)\n",
      "  • Interaction Features: Product of related features (BMI×HighBP, Age×BMI, GenHlth×PhysActivity)\n",
      "Feature engineering completed. New shape: (183824, 33)\n",
      "Feature engineering completed. New shape: (45957, 33)\n",
      "Feature engineering completed. New shape: (456129, 33)\n",
      "\n",
      "Feature engineering completed\n",
      "Original features:  21\n",
      "Engineered features: 33\n",
      "New features added:  12\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 2. FEATURE ENGINEERING\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 2: FEATURE ENGINEERING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nAPPLYING FEATURE ENGINEERING:\")\n",
    "print(\"-\" * 60)\n",
    "print(\"Creating new features:\")\n",
    "print(\"  • HealthRiskScore: Sum of risk factors (HighBP, HighChol, Stroke, etc.)\")\n",
    "print(\"  • LifestyleScore: Sum of positive health habits (PhysActivity, Fruits, Veggies)\")\n",
    "print(\"  • BMI Categories: One-hot encoded BMI groups (Underweight, Normal, Overweight, Obese)\")\n",
    "print(\"  • Age Groups: One-hot encoded age groups (Young, Middle, Senior)\")\n",
    "print(\"  • Interaction Features: Product of related features (BMI×HighBP, Age×BMI, GenHlth×PhysActivity)\")\n",
    "\n",
    "# Apply feature engineering to all three datasets\n",
    "# This creates composite features that may have better predictive power\n",
    "# than individual features alone\n",
    "features_train_eng = apply_all_feature_engineering(features_train)\n",
    "features_test_eng = apply_all_feature_engineering(features_test)\n",
    "features_train_smote_eng = apply_all_feature_engineering(features_train_smote)\n",
    "\n",
    "# Display feature engineering results\n",
    "print(\"\\nFeature engineering completed\")\n",
    "print(f\"Original features:  {features_train.shape[1]}\")\n",
    "print(f\"Engineered features: {features_train_eng.shape[1]}\")\n",
    "print(f\"New features added:  {features_train_eng.shape[1] - features_train.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3648951",
   "metadata": {},
   "source": [
    "# Scale New Continuous Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19aa4ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEP 3: SCALE NEW CONTINUOUS FEATURES\n",
      "================================================================================\n",
      "\n",
      "SCALING NEW CONTINUOUS FEATURES:\n",
      "------------------------------------------------------------\n",
      "Features to scale: ['HealthRiskScore', 'LifestyleScore', 'BMI_x_HighBP', 'Age_x_BMI', 'GenHlth_x_PhysActivity']\n",
      "\n",
      "New continuous features scaled\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 3. SCALE NEW CONTINUOUS FEATURES\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 3: SCALE NEW CONTINUOUS FEATURES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Identify new continuous features that need scaling\n",
    "# These are the newly created features that have continuous values\n",
    "# Scaling ensures all features have similar ranges (mean=0, std=1)\n",
    "new_continuous_features = ['HealthRiskScore', 'LifestyleScore', 'BMI_x_HighBP', \n",
    "                           'Age_x_BMI', 'GenHlth_x_PhysActivity']\n",
    "\n",
    "print(\"\\nSCALING NEW CONTINUOUS FEATURES:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Features to scale: {new_continuous_features}\")\n",
    "\n",
    "# Initialize StandardScaler for new features\n",
    "# StandardScaler: (x - mean) / std\n",
    "scaler_new = StandardScaler()\n",
    "\n",
    "# Fit scaler on training data and transform training set\n",
    "# fit_transform() calculates mean and std from training data\n",
    "features_train_eng[new_continuous_features] = scaler_new.fit_transform(\n",
    "    features_train_eng[new_continuous_features]\n",
    ")\n",
    "\n",
    "# Transform test set using training statistics\n",
    "# Important: Use transform() only (not fit_transform()) to avoid data leakage\n",
    "features_test_eng[new_continuous_features] = scaler_new.transform(\n",
    "    features_test_eng[new_continuous_features]\n",
    ")\n",
    "\n",
    "# Transform SMOTE training set using same statistics\n",
    "# This ensures consistency across all datasets\n",
    "features_train_smote_eng[new_continuous_features] = scaler_new.transform(\n",
    "    features_train_smote_eng[new_continuous_features]\n",
    ")\n",
    "\n",
    "print(\"\\nNew continuous features scaled\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpp-template (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
